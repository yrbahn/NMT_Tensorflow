{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import vocab\n",
    "from seq2seq_model import Seq2Seq\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "tf.logging.set_verbosity(tf.logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.__version__\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "# params\n",
    "HParams = namedtuple(\n",
    "  \"HParams\",\n",
    "  [ \"cell\",\n",
    "    \"batch_size\",\n",
    "    \"layers\",\n",
    "    \"attention\",\n",
    "    \"source_vocab_path\",\n",
    "    \"target_vocab_path\",\n",
    "    \"rl_training\",  \n",
    "    \"enc_embedding_dim\",\n",
    "    \"dec_embedding_dim\",\n",
    "    \"hidden_size\",\n",
    "    \"attn_size\",\n",
    "    \"eval_batch_size\",\n",
    "    \"learning_rate\",\n",
    "    \"max_source_len\",\n",
    "    \"max_target_len\",\n",
    "    \"optimizer\",\n",
    "    \"optimizer_clip_gradients\"])\n",
    "\n",
    "# create params\n",
    "def create_hparams():\n",
    "    return HParams(\n",
    "        cell=tf.contrib.rnn.LSTMCell,\n",
    "        batch_size=32,\n",
    "        rl_training=False,\n",
    "        source_vocab_path='./data/vocab_en.txt',\n",
    "        target_vocab_path='./data/vocab_kr.txt',\n",
    "        layers=8,\n",
    "        eval_batch_size=1,\n",
    "        attention=True,\n",
    "        optimizer=\"Adam\",\n",
    "        optimizer_clip_gradients=10.0,\n",
    "        learning_rate=0.001,\n",
    "        enc_embedding_dim=128,\n",
    "        dec_embedding_dim=128,\n",
    "        hidden_size=256,\n",
    "        attn_size=256,\n",
    "        max_source_len=40,\n",
    "        max_target_len=40)\n",
    "hparams = create_hparams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VocabInfo(path='./data/vocab_en.txt', vocab_size=10124, special_vocab=SpecialVocab(UNK=10124, SEQUENCE_START=10125, SEQUENCE_END=10126))\n",
      "12413\n"
     ]
    }
   ],
   "source": [
    "#vocab info loading\n",
    "source_vocab_info = vocab.get_vocab_info(hparams.source_vocab_path)\n",
    "target_vocab_info = vocab.get_vocab_info(hparams.target_vocab_path)\n",
    "print(source_vocab_info)\n",
    "print(target_vocab_info.special_vocab.SEQUENCE_END)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## input_fn 생성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from input_fn import create_input_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_fn = create_input_fn(source_file_list=['data/kaist_corpus_bpe.en'],\n",
    "                           target_file_list=['data/kaist_corpus_bpe.kr'],\n",
    "                           batch_size=hparams.batch_size)\n",
    "                           \n",
    "#features, labels = input_fn()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'source_len': array([ 6,  3,  6,  7,  8,  7,  7,  6,  5,  4,  8,  6,  5,  4, 14,  5,  7,\n",
      "        6,  7,  9,  5,  6,  7,  7, 10,  5,  6,  5,  6,  7,  5,  4], dtype=int32), 'source_tokens': array([[b'He', b'is', b'at', b'the', b'school.', b'SEQUENCE_END', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b''],\n",
      "       [b'Take', b'care.', b'SEQUENCE_END', b'', b'', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b''],\n",
      "       [b'P@@', b'or@@', b't', b'arms', b'!', b'SEQUENCE_END', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b''],\n",
      "       [b'He', b'th@@', b'undered', b'at', b'the', b'door.',\n",
      "        b'SEQUENCE_END', b'', b'', b'', b'', b'', b'', b''],\n",
      "       [b'There', b'is', b'a', b'great', b'need', b'of', b'money.',\n",
      "        b'SEQUENCE_END', b'', b'', b'', b'', b'', b''],\n",
      "       [b'He', b'is', b'ten', b'years', b'old', b'.', b'SEQUENCE_END', b'',\n",
      "        b'', b'', b'', b'', b'', b''],\n",
      "       [b'P@@', b'or@@', b't@@', b'land', b'B@@', b'bill.',\n",
      "        b'SEQUENCE_END', b'', b'', b'', b'', b'', b'', b''],\n",
      "       [b'P@@', b'res@@', b'ent', b'arms', b'!', b'SEQUENCE_END', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b''],\n",
      "       [b'He', b'is', b'f@@', b'our.', b'SEQUENCE_END', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b''],\n",
      "       [b'The', b'E@@', b'end.', b'SEQUENCE_END', b'', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b''],\n",
      "       [b'The', b'front', b'door', b'opens', b'on', b'the', b'street.',\n",
      "        b'SEQUENCE_END', b'', b'', b'', b'', b'', b''],\n",
      "       [b'His', b'ears', b'decei@@', b'ved', b'him.', b'SEQUENCE_END', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b''],\n",
      "       [b\"Who's\", b'cal@@', b'l@@', b'ing?', b'SEQUENCE_END', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b''],\n",
      "       [b\"He's\", b'a', b'student.', b'SEQUENCE_END', b'', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b''],\n",
      "       [b'Mean@@', b'whi@@', b'le@@', b',we', b'wish', b'to', b'thank',\n",
      "        b'you', b'for', b'your', b'kind', b'serv@@', b'ices.',\n",
      "        b'SEQUENCE_END'],\n",
      "       [b'Call', b'the', b'doctor', b'in.', b'SEQUENCE_END', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b''],\n",
      "       [b'A', b'difficulty', b'is', b'ag@@', b'grav@@', b'ated.',\n",
      "        b'SEQUENCE_END', b'', b'', b'', b'', b'', b'', b''],\n",
      "       [b'Come', b'back', b'some', b'other', b'day.', b'SEQUENCE_END', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b''],\n",
      "       [b'shru@@', b'g', b'off', b'drow@@', b's@@', b'iness',\n",
      "        b'SEQUENCE_END', b'', b'', b'', b'', b'', b'', b''],\n",
      "       [b'God', b'created', b'the', b'heav@@', b'en', b'and', b'the',\n",
      "        b'earth.', b'SEQUENCE_END', b'', b'', b'', b'', b''],\n",
      "       [b'keep', b\"one's\", b'cap', b'on', b'SEQUENCE_END', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b''],\n",
      "       [b'revol@@', b't', b'against', b'explo@@', b'itation',\n",
      "        b'SEQUENCE_END', b'', b'', b'', b'', b'', b'', b'', b''],\n",
      "       [b'He', b'is', b'fifteen', b'years', b'old', b'.', b'SEQUENCE_END',\n",
      "        b'', b'', b'', b'', b'', b'', b''],\n",
      "       [b'fish', b'for', b'fame', b'and', b'hon@@', b'ours',\n",
      "        b'SEQUENCE_END', b'', b'', b'', b'', b'', b'', b''],\n",
      "       [b'He', b'was', b'sick', b'with', b'p@@', b'ne@@', b'um@@',\n",
      "        b'oni@@', b'a.', b'SEQUENCE_END', b'', b'', b'', b''],\n",
      "       [b'The', b'ship', b'san@@', b'k.', b'SEQUENCE_END', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b''],\n",
      "       [b'H', b'Bir@@', b'th@@', b'day', b'.', b'SEQUENCE_END', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b''],\n",
      "       [b'He', b'is', b'fif@@', b'ty.', b'SEQUENCE_END', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b''],\n",
      "       [b'Jones', b'S@@', b'sa@@', b'hi@@', b'b.', b'SEQUENCE_END', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b''],\n",
      "       [b'He', b'is', b'clo@@', b'yed', b'with', b'pleasure.',\n",
      "        b'SEQUENCE_END', b'', b'', b'', b'', b'', b'', b''],\n",
      "       [b'man', b'is', b'mortal@@', b'.', b'SEQUENCE_END', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b''],\n",
      "       [b'stand', b'for', b'Parliament', b'SEQUENCE_END', b'', b'', b'',\n",
      "        b'', b'', b'', b'', b'', b'', b'']], dtype=object)}, {'target_tokens': array([[b'SEQUENCE_START', b'\\xea\\xb7\\xb8\\xeb\\x8a\\x94',\n",
      "        b'\\xed\\x95\\x99\\xea\\xb5\\x90\\xec\\x97\\x90',\n",
      "        b'\\xeb\\x8b\\xa4\\xeb\\x8b\\x88@@', b'\\xea\\xb3\\xa0',\n",
      "        b'\\xec\\x9e\\x88\\xeb\\x8b\\xa4.', b'SEQUENCE_END', b'', b'', b''],\n",
      "       [b'SEQUENCE_START', b'\\xec\\xa1\\xb0\\xec\\x8b\\xac@@', b'\\xed\\x95\\xb4!',\n",
      "        b'SEQUENCE_END', b'', b'', b'', b'', b'', b''],\n",
      "       [b'SEQUENCE_START', b'\\xea\\xb1\\xb0@@', b'\\xec\\xb4\\x9d@@', b'!',\n",
      "        b'SEQUENCE_END', b'', b'', b'', b'', b''],\n",
      "       [b'SEQUENCE_START', b'\\xea\\xb7\\xb8\\xeb\\x8a\\x94',\n",
      "        b'\\xeb\\xa7\\xb9\\xeb\\xa0\\xac\\xed\\x9e\\x88',\n",
      "        b'\\xeb\\xac\\xb8\\xec\\x9d\\x84',\n",
      "        b'\\xeb\\x91\\x90\\xeb\\x93\\x9c\\xeb\\xa0\\xb8\\xeb\\x8b\\xa4.',\n",
      "        b'SEQUENCE_END', b'', b'', b'', b''],\n",
      "       [b'SEQUENCE_START', b'\\xeb\\xaa\\xb9\\xec\\x8b\\x9c',\n",
      "        b'\\xeb\\x8f\\x88\\xec\\x9d\\x84',\n",
      "        b'\\xed\\x95\\x84\\xec\\x9a\\x94\\xeb\\xa1\\x9c',\n",
      "        b'\\xed\\x95\\x98\\xeb\\x8b\\xa4.', b'SEQUENCE_END', b'', b'', b'', b''],\n",
      "       [b'SEQUENCE_START', b'\\xea\\xb7\\xb8\\xeb\\x8a\\x94', b'\\xec\\x97\\xb4',\n",
      "        b'\\xec\\x82\\xb4\\xec\\x9d\\xb4\\xeb\\x8b\\xa4.', b'SEQUENCE_END', b'',\n",
      "        b'', b'', b'', b''],\n",
      "       [b'SEQUENCE_START', b'\\xed\\x8f\\xac@@', b'\\xed\\x8b\\x80@@',\n",
      "        b'\\xeb\\x9e\\x9c\\xeb\\x93\\x9c', b'SEQUENCE_END', b'', b'', b'', b'',\n",
      "        b''],\n",
      "       [b'SEQUENCE_START', b'\\xeb\\xb0\\x9b@@', b'\\xeb\\x93\\xa4\\xec\\x96\\xb4',\n",
      "        b'\\xec\\xb4\\x9d@@', b',', b'\\xea\\xb2\\xbd@@', b'\\xeb\\xa1\\x80@@',\n",
      "        b'!', b'SEQUENCE_END', b''],\n",
      "       [b'SEQUENCE_START', b'\\xea\\xb7\\xb8\\xeb\\x8a\\x94', b'\\xeb\\x84\\xa4',\n",
      "        b'\\xec\\x82\\xb4\\xec\\x9d\\xb4\\xeb\\x8b\\xa4.', b'SEQUENCE_END', b'',\n",
      "        b'', b'', b'', b''],\n",
      "       [b'SEQUENCE_START', b'\\xeb\\x81\\x9d@@', b'.', b'SEQUENCE_END', b'',\n",
      "        b'', b'', b'', b'', b''],\n",
      "       [b'SEQUENCE_START', b'\\xec\\xa0\\x95@@', b'\\xeb\\xac\\xb8\\xec\\x9d\\xb4',\n",
      "        b'\\xea\\xb1\\xb0\\xeb\\xa6\\xac\\xec\\x97\\x90',\n",
      "        b'\\xec\\xa0\\x91\\xed\\x95\\xb4', b'\\xec\\x9e\\x88\\xeb\\x8b\\xa4.',\n",
      "        b'SEQUENCE_END', b'', b'', b''],\n",
      "       [b'SEQUENCE_START', b'\\xea\\xb7\\xb8\\xeb\\x8a\\x94',\n",
      "        b'\\xec\\x9e\\x98\\xeb\\xaa\\xbb',\n",
      "        b'\\xeb\\x93\\xa4\\xec\\x97\\x88\\xeb\\x8b\\xa4.', b'SEQUENCE_END', b'',\n",
      "        b'', b'', b'', b''],\n",
      "       [b'SEQUENCE_START', b'\\xeb\\x8b\\xb9\\xec\\x8b\\xa0\\xec\\x9d\\x80',\n",
      "        b'\\xeb\\x88\\x84\\xea\\xb5\\xac@@',\n",
      "        b'\\xec\\x8b\\xad\\xeb\\x8b\\x88\\xea\\xb9\\x8c?', b'SEQUENCE_END', b'',\n",
      "        b'', b'', b'', b''],\n",
      "       [b'SEQUENCE_START', b'\\xea\\xb7\\xb8\\xeb\\x8a\\x94',\n",
      "        b'\\xed\\x95\\x99\\xec\\x83\\x9d\\xec\\x9d\\xb4\\xeb\\x8b\\xa4.',\n",
      "        b'SEQUENCE_END', b'', b'', b'', b'', b'', b''],\n",
      "       [b'SEQUENCE_START', b'\\xec\\x95\\x84\\xec\\x9a\\xb8\\xeb\\x9f\\xac',\n",
      "        b'\\xea\\xb0\\x90\\xec\\x82\\xac\\xec\\x9d\\x98',\n",
      "        b'\\xeb\\x9c\\xbb\\xec\\x9d\\x84',\n",
      "        b'\\xed\\x91\\x9c\\xed\\x95\\xa9\\xeb\\x8b\\x88\\xeb\\x8b\\xa4.',\n",
      "        b'SEQUENCE_END', b'', b'', b'', b''],\n",
      "       [b'SEQUENCE_START', b'\\xec\\x9d\\x98\\xec\\x82\\xac\\xeb\\xa5\\xbc',\n",
      "        b'\\xeb\\xb6\\x88\\xeb\\x9f\\xac@@',\n",
      "        b'\\xec\\x98\\xa4\\xec\\x84\\xb8\\xec\\x9a\\x94.', b'SEQUENCE_END', b'',\n",
      "        b'', b'', b'', b''],\n",
      "       [b'SEQUENCE_START', b'\\xea\\xb3\\xa4\\xeb\\x9e\\x80@@', b'\\xec\\x9d\\xb4',\n",
      "        b'\\xea\\xb0\\x80@@', b'\\xec\\xa4\\x91@@', b'\\xeb\\x90\\x9c\\xeb\\x8b\\xa4.',\n",
      "        b'SEQUENCE_END', b'', b'', b''],\n",
      "       [b'SEQUENCE_START', b'\\xeb\\x8b\\xa4\\xeb\\xa5\\xb8',\n",
      "        b'\\xeb\\x82\\xa0\\xec\\x97\\x90', b'\\xeb\\x8b\\xa4\\xec\\x8b\\x9c',\n",
      "        b'\\xec\\x99\\x80\\xeb\\x9d\\xbc.', b'SEQUENCE_END', b'', b'', b'', b''],\n",
      "       [b'SEQUENCE_START', b'\\xec\\xa1\\xb8@@', b'\\xec\\x9d\\x8c\\xec\\x9d\\x84',\n",
      "        b'\\xec\\xab\\x93@@', b'\\xeb\\x8b\\xa4', b'SEQUENCE_END', b'', b'', b'',\n",
      "        b''],\n",
      "       [b'SEQUENCE_START', b'\\xec\\x8b\\xa0\\xec\\x9d\\x80', b'\\xec\\xb2\\x9c@@',\n",
      "        b'\\xec\\xa7\\x80\\xeb\\xa5\\xbc', b'\\xec\\xb0\\xbd\\xec\\xa1\\xb0@@',\n",
      "        b'\\xed\\x96\\x88\\xeb\\x8b\\xa4.', b'SEQUENCE_END', b'', b'', b''],\n",
      "       [b'SEQUENCE_START', b'\\xeb\\xaa\\xa8\\xec\\x9e\\x90\\xeb\\xa5\\xbc',\n",
      "        b'\\xec\\x93\\xb0\\xea\\xb3\\xa0', b'\\xec\\x9e\\x88\\xeb\\x8b\\xa4',\n",
      "        b'SEQUENCE_END', b'', b'', b'', b'', b''],\n",
      "       [b'SEQUENCE_START', b'\\xec\\xb0\\xa9\\xec\\xb7\\xa8@@', b'\\xec\\x97\\x90',\n",
      "        b'\\xeb\\xb0\\x98\\xed\\x95\\xad@@', b'\\xed\\x95\\x98\\xeb\\x8b\\xa4',\n",
      "        b'SEQUENCE_END', b'', b'', b'', b''],\n",
      "       [b'SEQUENCE_START', b'\\xea\\xb7\\xb8\\xeb\\x8a\\x94', b'\\xec\\x97\\xb4@@',\n",
      "        b'\\xeb\\x8b\\xa4\\xec\\x84\\xaf',\n",
      "        b'\\xec\\x82\\xb4\\xec\\x9d\\xb4\\xeb\\x8b\\xa4.', b'SEQUENCE_END', b'',\n",
      "        b'', b'', b''],\n",
      "       [b'SEQUENCE_START', b'\\xec\\x98\\xa8\\xea\\xb0\\x96',\n",
      "        b'\\xec\\x88\\x98\\xeb\\x8b\\xa8\\xec\\x9d\\x84', b'\\xeb\\xb6\\x80@@',\n",
      "        b'\\xeb\\xa0\\xa4', b'\\xeb\\xaa\\x85\\xec\\x98\\x88\\xeb\\xa5\\xbc',\n",
      "        b'\\xec\\xb6\\x94@@', b'\\xea\\xb5\\xac@@', b'\\xed\\x95\\x98\\xeb\\x8b\\xa4',\n",
      "        b'SEQUENCE_END'],\n",
      "       [b'SEQUENCE_START', b'\\xea\\xb7\\xb8\\xeb\\x8a\\x94', b'\\xed\\x8f\\x90@@',\n",
      "        b'\\xeb\\xa0\\xb4@@', b'\\xec\\x9d\\x84', b'\\xec\\x95\\x93@@',\n",
      "        b'\\xec\\x95\\x98\\xeb\\x8b\\xa4.', b'SEQUENCE_END', b'', b''],\n",
      "       [b'SEQUENCE_START', b'\\xeb\\xb0\\xb0\\xea\\xb0\\x80',\n",
      "        b'\\xec\\xb9\\xa8\\xeb\\xaa\\xb0@@', b'\\xed\\x96\\x88\\xeb\\x8b\\xa4.',\n",
      "        b'SEQUENCE_END', b'', b'', b'', b'', b''],\n",
      "       [b'SEQUENCE_START', b'\\xec\\x83\\x9d\\xec\\x9d\\xbc',\n",
      "        b'\\xec\\xb6\\x95\\xed\\x95\\x98@@', b'\\xed\\x95\\xb4!', b'SEQUENCE_END',\n",
      "        b'', b'', b'', b'', b''],\n",
      "       [b'SEQUENCE_START', b'\\xea\\xb7\\xb8\\xeb\\x8a\\x94', b'50@@',\n",
      "        b'\\xec\\x84\\xb8\\xec\\x9d\\xb4\\xeb\\x8b\\xa4.', b'SEQUENCE_END', b'',\n",
      "        b'', b'', b'', b''],\n",
      "       [b'SEQUENCE_START', b'\\xec\\xa1\\xb4\\xec\\x8a\\xa4@@',\n",
      "        b'\\xec\\x94\\xa8@@', b'.', b'SEQUENCE_END', b'', b'', b'', b'', b''],\n",
      "       [b'SEQUENCE_START', b'\\xea\\xb7\\xb8\\xeb\\x8a\\x94', b'\\xec\\xa7\\x88@@',\n",
      "        b'\\xeb\\xa6\\xac\\xeb\\x8f\\x84\\xeb\\xa1\\x9d',\n",
      "        b'\\xeb\\x86\\x80\\xec\\x95\\x98\\xeb\\x8b\\xa4.', b'SEQUENCE_END', b'',\n",
      "        b'', b'', b''],\n",
      "       [b'SEQUENCE_START', b'\\xec\\x82\\xac\\xeb\\x9e\\x8c\\xec\\x9d\\x80',\n",
      "        b'\\xeb\\x8b\\xa4', b'\\xec\\xa3\\xbd\\xeb\\x8a\\x94\\xeb\\x8b\\xa4.',\n",
      "        b'SEQUENCE_END', b'', b'', b'', b'', b''],\n",
      "       [b'SEQUENCE_START', b'\\xec\\x9d\\x98@@', b'\\xec\\x9b\\x90',\n",
      "        b'\\xec\\x84\\xa0\\xea\\xb1\\xb0\\xec\\x97\\x90',\n",
      "        b'\\xec\\x9e\\x85\\xed\\x9b\\x84\\xeb\\xb3\\xb4@@',\n",
      "        b'\\xed\\x95\\x98\\xeb\\x8b\\xa4', b'SEQUENCE_END', b'', b'', b'']], dtype=object), 'target_len': array([ 7,  4,  5,  6,  6,  5,  5,  9,  5,  4,  7,  5,  5,  4,  6,  5,  7,\n",
      "        6,  6,  7,  5,  6,  6, 10,  8,  5,  5,  5,  5,  6,  5,  7], dtype=int32)}]\n"
     ]
    }
   ],
   "source": [
    "## check input_fn\n",
    "# loading vocab\n",
    "# 데이타 체크\n",
    "def callInputFnOnce(input_fn, session): \n",
    "    features, label = input_fn()\n",
    "    coord =  tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(session, coord=coord)\n",
    "    result_values = session.run([features, label])\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)\n",
    "    return result_values\n",
    "\n",
    "print(callInputFnOnce(input_fn, tf.Session()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## seq2seq 모델생성\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# seq2seq모델 생성\n",
    "seq2seq = Seq2Seq(target_vocab_info.special_vocab.SEQUENCE_START, \n",
    "                  target_vocab_info.special_vocab.SEQUENCE_END,\n",
    "                  hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f8ec0381a58>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': None}\n"
     ]
    }
   ],
   "source": [
    "seq2seq_estimator = tf.contrib.learn.Estimator(\n",
    "    model_fn=seq2seq.create_model_fn(), params=hparams, model_dir=\"./model_test/\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f8f81d9bb38>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': None}\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Creating vocabulary lookup table of size 10127\n",
      "INFO:tensorflow:Creating vocabulary lookup table of size 12414\n",
      "Tensor(\"Decoder/cond/PyFunc:0\", dtype=float32)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unexpected shape <unknown> for Decoder/cond/Merge_2:0.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-5ee467f0c8c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#training...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mseq2seq_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/hanmail/.pyenv/versions/anaconda3-4.3.1/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0m_call_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorator_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_qualified_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m             func.__module__, arg_name, date, instructions)\n\u001b[0;32m--> 281\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m     new_func.__doc__ = _add_deprecated_arg_notice_to_docstring(\n\u001b[1;32m    283\u001b[0m         func.__doc__, date, instructions)\n",
      "\u001b[0;32m/hanmail/.pyenv/versions/anaconda3-4.3.1/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, input_fn, steps, batch_size, monitors, max_steps)\u001b[0m\n\u001b[1;32m    428\u001b[0m       \u001b[0mhooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbasic_session_run_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStopAtStepHook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/hanmail/.pyenv/versions/anaconda3-4.3.1/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks)\u001b[0m\n\u001b[1;32m    925\u001b[0m       \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 927\u001b[0;31m       \u001b[0mmodel_fn_ops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_train_ops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    928\u001b[0m       \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLOSSES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_fn_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m       all_hooks.extend([\n",
      "\u001b[0;32m/hanmail/.pyenv/versions/anaconda3-4.3.1/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\u001b[0m in \u001b[0;36m_get_train_ops\u001b[0;34m(self, features, labels)\u001b[0m\n\u001b[1;32m   1130\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0mModelFnOps\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m     \"\"\"\n\u001b[0;32m-> 1132\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_model_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_fn_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_get_eval_ops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/hanmail/.pyenv/versions/anaconda3-4.3.1/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\u001b[0m in \u001b[0;36m_call_model_fn\u001b[0;34m(self, features, labels, mode)\u001b[0m\n\u001b[1;32m   1101\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'model_dir'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_fn_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_dir'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1103\u001b[0;31m     \u001b[0mmodel_fn_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_fn_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_fn_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModelFnOps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data1/users/yrbahn/work/NMT_tensorflow/seq2seq_model.py\u001b[0m in \u001b[0;36mmodel_fn\u001b[0;34m(features, labels, params, mode)\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_optimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m                 return model_fn_lib.ModelFnOps(\n",
      "\u001b[0;32m/data1/users/yrbahn/work/NMT_tensorflow/seq2seq_model.py\u001b[0m in \u001b[0;36m_add_optimizer\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    354\u001b[0m                 \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m                 \u001b[0mclip_gradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_clip_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m                 optimizer=self.params.optimizer)\n\u001b[0m\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m     \u001b[0;31m# create model_fn for estimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/hanmail/.pyenv/versions/anaconda3-4.3.1/lib/python3.6/site-packages/tensorflow/contrib/layers/python/layers/optimizers.py\u001b[0m in \u001b[0;36moptimize_loss\u001b[0;34m(loss, global_step, learning_rate, optimizer, gradient_noise_scale, gradient_multipliers, clip_gradients, learning_rate_decay_fn, update_ops, variables, name, summaries, colocate_gradients_with_ops, increment_global_step)\u001b[0m\n\u001b[1;32m    151\u001b[0m   \"\"\"\n\u001b[1;32m    152\u001b[0m   \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m   \u001b[0mcontrib_framework\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mglobal_step\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0mglobal_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontrib_framework\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_global_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/hanmail/.pyenv/versions/anaconda3-4.3.1/lib/python3.6/site-packages/tensorflow/contrib/framework/python/framework/tensor_util.py\u001b[0m in \u001b[0;36massert_scalar\u001b[0;34m(tensor, name)\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndims\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unexpected shape %s for %s.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unexpected shape <unknown> for Decoder/cond/Merge_2:0."
     ]
    }
   ],
   "source": [
    "#training...\n",
    "seq2seq_estimator.fit(input_fn=input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def infer_input_fn(source_seq):\n",
    "    source_seq = [source_seq.split()]\n",
    "    source_seq_len = len(source_seq)\n",
    "    source_seq = tf.constant(source_seq, dtype=tf.string)\n",
    "    source_seq_len = tf.constant([source_seq_len], dtype=tf.int32)\n",
    "        \n",
    "    features = {\"source_tokens\": source_seq, \"source_len\": source_seq_len}\n",
    "    print(features)\n",
    "    return features, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RLEstimator 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = seq2seq.predict(input_fn=lambda :infer_input_fn(\"i am boy\"))\n",
    "for i, p in enumerate(predictions):\n",
    "    print(p)\n",
    "    predicted_tokens = np.char.decode(p.astype(\"S\"), \"utf-8\")\n",
    "    print(' '.join(predicted_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
