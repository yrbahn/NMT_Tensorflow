{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EASY_MODE = True\n",
    "\n",
    "MODE = \"he-to-en\"\n",
    "END = ';'  \n",
    "MAX_OUTPUT_LENGTH = 50 if not EASY_MODE else 20\n",
    "REPORT_FREQ       = 100    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step1.  전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anarchism\tאנרכיזם\r\n",
      "Autism\tאוטיזם קלאסי\r\n",
      "Albedo\tאלבדו\r\n",
      "A\tA\r\n",
      "Alabama\tאלבמה\r\n",
      "Achilles\tאכילס\r\n",
      "Abraham Lincoln\tאברהם לינקולן\r\n",
      "Aristotle\tאריסטו\r\n",
      "An American in Paris\tאמריקאי בפריז\r\n",
      "Academy Awards\tפרס אוסקר\r\n"
     ]
    }
   ],
   "source": [
    "! head -n 10 data/main_dataset.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size =  130699\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "word_to_translation = defaultdict(list)\n",
    "\n",
    "with open(\"data/main_dataset.txt\") as fin:\n",
    "    for line in fin:\n",
    "        en, he = line[:-1].lower().replace(END,' ').split('\\t')\n",
    "        word, trans = (he,en) if MODE=='he-to-en' else (en,he)\n",
    "        if EASY_MODE:\n",
    "            if max(len(word), len(trans)) > 20:\n",
    "                continue\n",
    "        word_to_translation[word+END].append(trans+END)\n",
    "        \n",
    "print(\"size = \", len(word_to_translation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ס': 0, 'ת': 1, '4': 2, 'ص': 3, 'ش': 4, 'ぺ': 5, '0': 6, '8': 7, 'ּ': 8, 'ÿ': 9, 'e': 10, 'ñ': 11, '≤': 12, 'ک': 13, 'ﭪ': 14, 'ß': 15, 'خ': 16, 'い': 17, 'т': 18, 'è': 19, 'q': 20, 'é': 21, 'x': 22, 'a': 23, '°': 24, 'р': 25, '²': 26, '¡': 27, '•': 28, 'っ': 29, 'ấ': 30, 'ø': 31, '桜': 32, 'ф': 33, 'ך': 34, '5': 35, 'ט': 36, 'd': 37, '2': 38, 'ӎ': 39, 'c': 40, 'פ': 41, 'í': 42, 'ا': 43, 'i': 44, '仙': 45, '$': 46, 'в': 47, '猫': 48, 'س': 49, ':': 50, 'ע': 51, 'u': 52, 'у': 53, 'チ': 54, '–': 55, 'م': 56, 'п': 57, 'ӡ': 58, 'コ': 59, 'ӟ': 60, '/': 61, '9': 62, 'б': 63, 'm': 64, 'à': 65, '榎': 66, '門': 67, 'ر': 68, 'ה': 69, 'ц': 70, '′': 71, 'צ': 72, 'ĝ': 73, 'ら': 74, '×': 75, 'マ': 76, 'ѳ': 77, 'з': 78, 'о': 79, '\\\\': 80, 'n': 81, '子': 82, 'ם': 83, '*': 84, '!': 85, 'ت': 86, 'タ': 87, '&': 88, 'b': 89, '熊': 90, 'ח': 91, '־': 92, 'ě': 93, '∂': 94, 'ג': 95, 'و': 96, '守': 97, 'ò': 98, 'я': 99, 'ê': 100, '星': 101, 'r': 102, 'ִ': 103, 'е': 104, '@': 105, 'μ': 106, 'д': 107, ' ': 108, '-': 109, 'g': 110, 'ŋ': 111, 'ׁ': 112, 'ﭖ': 113, 'k': 114, 'と': 115, 'с': 116, 's': 117, 'ѯ': 118, 'ó': 119, '3': 120, 'ל': 121, 'ש': 122, 'ֵ': 123, 'ַ': 124, 'כ': 125, 'ו': 126, '(': 127, ',': 128, 'а': 129, 'l': 130, 'ר': 131, '+': 132, '1': 133, '一': 134, 'ú': 135, 'ָ': 136, 'ق': 137, 'ן': 138, 't': 139, 'ə': 140, '御': 141, 'х': 142, '’': 143, 'p': 144, 'ө': 145, 'י': 146, 'ю': 147, '−': 148, 'ء': 149, '.': 150, 'þ': 151, 'ی': 152, 'ғ': 153, 'ぼ': 154, 'ь': 155, 'נ': 156, 'ظ': 157, 'א': 158, 'ü': 159, 'ع': 160, 'w': 161, 'ҙ': 162, '·': 163, '♯': 164, 'ộ': 165, 'る': 166, 'ב': 167, 'ъ': 168, 'á': 169, 'ґ': 170, '野': 171, 'г': 172, \"'\": 173, '׳': 174, 'ы': 175, 'ד': 176, 'z': 177, 'л': 178, 'ף': 179, 'ض': 180, '白': 181, 'ń': 182, 'ĵ': 183, '″': 184, ')': 185, 'и': 186, '½': 187, 'v': 188, 'h': 189, 'ف': 190, 'ĉ': 191, 'ж': 192, 'ш': 193, 'j': 194, 'ז': 195, 'ֿ': 196, 'ŝ': 197, 'ѻ': 198, '#': 199, 'č': 200, 'ﭺ': 201, ';': 202, 'к': 203, '7': 204, 'ױ': 205, 'o': 206, '\"': 207, 'ژ': 208, '=': 209, 'ç': 210, 'ץ': 211, '?': 212, 'џ': 213, 'y': 214, 'מ': 215, 'ث': 216, 'щ': 217, 'f': 218, 'н': 219, 'ل': 220, 'ѓ': 221, '6': 222, 'ŭ': 223, 'ק': 224, 'گ': 225, 'ö': 226, 'あ': 227, 'š': 228, 'ذ': 229, 'غ': 230}\n",
      "231\n"
     ]
    }
   ],
   "source": [
    "# 소스 언어에서 모든 유니크한 문자를 구하자(a.k.a 소스 사전)\n",
    "all_words = list(word_to_translation.keys())\n",
    "source_letters = list(set(''.join(all_words)))\n",
    "source_to_ix = {l:i for i,l in enumerate(source_letters)}\n",
    "print(source_to_ix)\n",
    "print(len(source_to_ix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ס', 'ת', 'ḫ', '4', 'ħ', 'σ', 'ص', '`', 'û', '0', 'ぺ', '8', 'ą', 'ÿ', 'e', 'ñ', 'ế', '≤', 'ک', 'ő', 'ß', 'ṯ', 'ļ', 'い', 'т', 'ô', 'è', 'q', 'é', 'ù', 'ر', 'x', 'a', '°', '—', 'р', '²', 'î', '¡', '•', 'ı', 'ղ', 'っ', 'ấ', 'ø', '桜', 'τ', 'ф', '5', 'õ', 'ṇ', 'ľ', 'ט', 'd', 'ì', '老', '2', 'ơ', 'ẓ', 'ق', 'c', 'פ', 'í', 'ا', 'ý', 'ů', 'i', 'ớ', 'ḏ', '門', '$', 'в', '仙', '猫', 'ņ', 'س', ':', 'ḥ', 'π', 'ע', 'u', 'م', '–', 'ʻ', 'ż', 'チ', 'п', 'у', 'コ', 'վ', '%', '/', 'ș', '9', 'ű', 'υ', 'ŏ', 'm', 'à', 'ğ', '榎', 'ṃ', 'ה', 'â', 'ō', 'ĝ', 'ī', 'å', '′', '×', 'צ', 'ư', 'ï', 'マ', '…', 'ら', '̇', 'о', 'ỏ', 'n', 'ţ', '子', 'ε', 'ם', '*', '!', 'タ', 'ت', '&', 'b', '熊', 'ח', 'ḳ', 'ạ', 'η', 'ě', '∂', 'ồ', 'ג', 'و', 'ò', '守', 'я', 'ê', '星', 'ọ', 'ł', 'ʾ', 'r', 'ť', 'ģ', 'е', 'μ', 'µ', '@', 'կ', 'ʿ', ' ', 'g', '-', 'ŋ', 'k', 'と', 's', 'ó', 'ả', '3', 'ā', 'ל', 'ש', 'ē', 'δ', 'כ', 'ν', 'ו', '(', ',', 'а', 'l', '+', 'ר', 'œ', '1', '⋯', '一', 'ú', 'ş', '→', 'ן', 't', 'æ', 'ķ', 'ứ', 'ə', '御', 'ę', '~', 'ð', 'ň', 'զ', '’', 'p', 'י', 'ю', '−', '.', 'þ', '♭', 'ی', 'ぼ', 'ь', 'ū', 'ü', 'ė', 'נ', 'ã', 'א', 'ỹ', 'ع', 'w', 'ų', '·', 'ộ', 'ř', 'る', 'ב', '^', 'ъ', 'á', '‘', 'ď', '野', \"'\", 'ž', 'ы', 'ο', 'ד', 'z', 'ц', 'ɱ', 'л', 'ζ', 'ף', '白', 'ń', 'đ', 'ĵ', '″', '½', ')', 'и', 'v', 'h', 'ա', 'ĉ', 'ف', 'ễ', 'ш', 'j', 'ז', 'ä', 'ŝ', 'č', ';', 'к', '7', 'o', 'ë', 'ć', '\"', 'ț', 'ç', 'ḍ', '陳', '?', '=', 'ρ', 'y', 'מ', 'f', 'н', 'ل', '6', 'ր', 'ă', 'ή', 'ŭ', 'ק', 'ö', 'ź', 'あ', 'š', 'ś']\n"
     ]
    }
   ],
   "source": [
    "#타켓 언어에서 모든 유니크한 문자를 구하자\n",
    "all_translations = [ts for all_ts in word_to_translation.values() for ts in all_ts]\n",
    "target_letters = list(set([l for ts in all_translations for l in ts] + [\" \"]))\n",
    "target_to_ix = {l:i for i,l in enumerate(target_letters)}\n",
    "print(target_letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#특별한 토근들\n",
    "EOS_ix_source=source_letters.index(END)\n",
    "EOS_ix_target=target_letters.index(END)\n",
    "BOS_ix_target = target_letters.index(\" \")\n",
    "PAD_ix=EOS_ix_source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "작업의 범위를 예측하기위해 단어/번역 길이 분포를 그리자\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfcAAAEICAYAAABCsb3rAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n1fgOygAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2e0880deb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=[8,4])\n",
    "plt.subplot(1,2,1)\n",
    "plt.title(\"words\")\n",
    "plt.hist(list(map(len,all_words)),bins=25);\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.title('translations')\n",
    "plt.hist(list(map(len,all_translations)),bins=25);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 두번째 단계: 보조 함수들\n",
    "몇가지 헬퍼 함수가 필요하다:\n",
    "- 문자열로부터 데이타를 정수 행렬들로 바꾸기\n",
    "- 샘플 랜덤 미니배치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def as_matrix(sequences, token_to_i, max_len=None, PAX_ix=PAD_ix):\n",
    "    \"\"\"\n",
    "    가변 길이 토근 시퀀스를 고정된 크기의 행렬로 바꾸자.\n",
    "    사용 예제:\n",
    "    >>>print( as_matrix(words[:3],source_to_ix))\n",
    "    [[15 22 21 28 27 13 -1 -1 -1 -1 -1]\n",
    "     [30 21 15 15 21 14 28 27 13 -1 -1]\n",
    "     [25 37 31 34 21 20 37 21 28 19 13]]\n",
    "    \"\"\"\n",
    "    \n",
    "    max_len = max_len or max(map(len, sequences))\n",
    "    \n",
    "    matrix = np.zeros((len(sequences), max_len), dtype='int32') + PAD_ix\n",
    "    for i,seq in enumerate(sequences):\n",
    "        row_ix = list(map(token_to_i.get, seq))[:max_len]\n",
    "        matrix[i,:len(row_ix)] = row_ix\n",
    "    \n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "def sample_batch(words, word_to_translation, batch_size):\n",
    "    \"\"\"\n",
    "    각 단어에 대해 단어와 랜덤한 올바른 번역의 랜덤 배치를 샘플링하기\n",
    "    예제 사용법:\n",
    "        batch_x, batch_y = sample_batch(train_words, word_to_translations, 10)\n",
    "    \"\"\"\n",
    "    \n",
    "    #단어들 선택하기\n",
    "    batch_words = np.random.choice(words, size=batch_size)\n",
    "    batch_words_len = np.array(list(map(len, batch_words)))\n",
    "    \n",
    "    #번역 선택하기\n",
    "    batch_trans_candidates = list(map(word_to_translation.get, batch_words))\n",
    "    batch_trans = list(map(random.choice, batch_trans_candidates))\n",
    "    batch_trans_len = np.array(list(map(len, batch_trans)))\n",
    "    \n",
    "    return as_matrix(batch_words,source_to_ix), batch_words_len, \\\n",
    "        as_matrix(batch_trans,target_to_ix), batch_trans_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 셋 자르기\n",
    "모든 단어의 20퍼센트는 validation를 위해 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hanmail/.pyenv/versions/anaconda3-4.3.1/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "train_words,test_words = train_test_split(all_words,test_size=0.1,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3단계: encoder-decoder를 생성하기\n",
    "아키텍쳐는 두개의 주요 블록으로 구성된다:\n",
    "- Encoder는 단어들을 문자로 읽고 마지막 상태 벡터를 리턴한다.(일반적으로 마지막 RNN 상태 함수)\n",
    "- Decoder는 그 상태 벡터를 가지고 문자단위로 번역을 리턴한다\n",
    "\n",
    "이 섹션에서 encoder를 구현한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_mask_by_eos(is_eos):\n",
    "    \"\"\"takes indicator of \"it ends now\", returns mask.\n",
    "    Ignores everything after first end.\"\"\"\n",
    "    assert is_eos.ndim==2\n",
    "    is_right_after_eos = np.concatenate([np.zeros_like(is_eos[:,:1]),is_eos[:,:-1]],-1)\n",
    "    is_after_eos = np.eq(np.cumsum(is_right_after_eos,axis=-1),0).astype('uint8')\n",
    "    return is_after_eos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from collections import namedtuple\n",
    "\n",
    "# params\n",
    "HParams = namedtuple(\n",
    "  \"HParams\",\n",
    "  [\n",
    "    \"cell\",\n",
    "    \"batch_size\",\n",
    "    \"layers\",\n",
    "    \"attention\",\n",
    "    \"enc_embedding_dim\",\n",
    "    \"dec_embedding_dim\",\n",
    "    \"hidden_size\",\n",
    "    \"attn_size\",\n",
    "    \"eval_batch_size\",\n",
    "    \"learning_rate\",\n",
    "    \"max_source_len\",\n",
    "    \"max_target_len\",\n",
    "    \"output_keep_prob\",\n",
    "    \"optimizer\",\n",
    "    \"optimizer_clip_gradients\",\n",
    "    \"ckpt_path\"\n",
    "  ])\n",
    "\n",
    "# create params\n",
    "def create_hparams():\n",
    "    return HParams(\n",
    "        cell=tf.contrib.rnn.GRUCell,\n",
    "        batch_size=32,\n",
    "        layers=1,\n",
    "        attention=False,\n",
    "        eval_batch_size=1,\n",
    "        optimizer=\"Adam\",\n",
    "        optimizer_clip_gradients = 10.0,\n",
    "        learning_rate=0.001,\n",
    "        enc_embedding_dim=50,\n",
    "        dec_embedding_dim=50,\n",
    "        hidden_size=512,\n",
    "        attn_size=512,\n",
    "        output_keep_prob=0.5,\n",
    "        max_source_len=20,\n",
    "        max_target_len=MAX_OUTPUT_LENGTH,\n",
    "        ckpt_path='./ckpt_dir/model2.ckpt')\n",
    "hparams = create_hparams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/gpu:0', '/gpu:1', '/gpu:2', '/gpu:3', '/gpu:4', '/gpu:5', '/gpu:6', '/gpu:7']\n"
     ]
    }
   ],
   "source": [
    "#check gpu\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'GPU']\n",
    "print(get_available_gpus())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "Here we define functions for model inference (both greedy and sampled)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_mask_by_eos(is_eos):\n",
    "    \"\"\" \"지금 부터 끝이다\"의 표시를 가지고, mask를 리턴한다. \n",
    "    첫번째 마지막이후로 모든것을 무시한다. \n",
    "    [[False,False,True,True]] -> [[1,1,1,0]]\n",
    "    \"\"\"\n",
    "    assert is_eos.ndim==2\n",
    "    is_right_after_eos = np.concatenate([np.zeros_like(is_eos[:,:1]),is_eos[:,:-1]],-1)\n",
    "    is_after_eos = np.equal(np.cumsum(is_right_after_eos,axis=-1), 0).astype('uint8')\n",
    "    return is_after_eos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.layers.core import Dense\n",
    "from sample_embedding_helper import SampleEmbeddingHelper\n",
    "from tensorflow.python.ops.rnn_cell_impl import _zero_state_tensors\n",
    "from loss import rl_loss\n",
    "\n",
    "import os\n",
    "\n",
    "class Seq2SeqModel:\n",
    "    def __init__(self, config, mode='training', rl_enable=False):\n",
    "        self.config = config\n",
    "        self.mode = mode\n",
    "        self.max_target_len = self.config.max_target_len\n",
    "        self.available_gpus = get_available_gpus()\n",
    "        self.current_gpu_index = 0\n",
    "        self.rl_enable = rl_enable\n",
    "        self.total_gpu_cnt = len(self.available_gpus)\n",
    "        \n",
    "    def _get_next_gpu(self):\n",
    "        if self.total_gpu_cnt == 0:\n",
    "            return 'cpu:0'\n",
    "        else:\n",
    "            self.current_gpu_index += 1\n",
    "            self.current_gpu_index %= (self.total_gpu_cnt + 1)\n",
    "            return self.available_gpus[self.current_gpu_index-1]\n",
    "        \n",
    "    def _get_mask_by_eos(self, is_eos):\n",
    "        is_right_after_eos = tf.concat([tf.zeros_like(is_eos[:,:1]),is_eos[:,:-1]],-1)\n",
    "        is_after_eos = tf.equal(tf.cumsum(tf.to_float(is_right_after_eos),axis=-1), 0)\n",
    "        return tf.to_float(is_after_eos)\n",
    "    \n",
    "    # add placeholders\n",
    "    def _add_placeholders(self):\n",
    "        self.input_ids = tf.placeholder(\n",
    "            tf.int32,\n",
    "            shape=[None, None],\n",
    "            name='input_ids')\n",
    "\n",
    "        self.inputs_len = tf.placeholder(\n",
    "            tf.int32,\n",
    "            shape=[None],\n",
    "            name='inputs_len')\n",
    "        \n",
    "        if self.mode == 'training':\n",
    "            self.target_ids = tf.placeholder(\n",
    "                tf.int32,\n",
    "                shape=[None, None],\n",
    "                name='target_ids')\n",
    "\n",
    "            self.targets_len = tf.placeholder(\n",
    "                tf.int32,\n",
    "                shape=[None],\n",
    "                name='targets_len')\n",
    "                      \n",
    "            #self.rl_enable = False\n",
    "            \n",
    "            self.targets_length = tf.minimum(self.targets_len, self.config.max_target_len)\n",
    "            self.targets = self.target_ids[:, :self.max_target_len]\n",
    "                    \n",
    "    # build a computation graph\n",
    "    def build_graph(self, saver=None):\n",
    "        # add placeholder variables\n",
    "        self._add_placeholders()\n",
    "\n",
    "        # build encoder\n",
    "        self._add_encoder()\n",
    "        \n",
    "        # build decoder\n",
    "        self._add_decoder()\n",
    "            \n",
    "        #optimizer\n",
    "        if self.mode == 'training':\n",
    "            self._add_optimizer()\n",
    "        \n",
    "        if saver:\n",
    "            self.saver = saver\n",
    "        else:\n",
    "            self.saver = tf.train.Saver()\n",
    "\n",
    "    # encoder layer\n",
    "    def _add_encoder(self):\n",
    "        with tf.variable_scope('Encoder') as scope:\n",
    "            self.batch_size = tf.shape(self.input_ids)[0]\n",
    "\n",
    "            enc_W_emb = tf.get_variable('en_embedding', \n",
    "                                        initializer=tf.random_uniform([len(source_letters), self.config.enc_embedding_dim]),\n",
    "                                        dtype=tf.float32)\n",
    "            \n",
    "            enc_emb_inputs = tf.nn.embedding_lookup(\n",
    "                enc_W_emb, self.input_ids, name='emb_inputs')\n",
    "\n",
    "            # bidirectional rnn\n",
    "            if self.config.layers == 1:\n",
    "                enc_cell = tf.contrib.rnn.DeviceWrapper(\n",
    "                    tf.contrib.rnn.DropoutWrapper(\n",
    "                        self.config.cell(self.config.hidden_size),\n",
    "                        output_keep_prob=self.config.output_keep_prob),\n",
    "                    device=self._get_next_gpu())\n",
    "                \n",
    "                self.enc_outputs, self.enc_last_state = tf.nn.dynamic_rnn(\n",
    "                    cell=enc_cell,\n",
    "                    inputs=enc_emb_inputs,\n",
    "                    sequence_length=self.inputs_len,\n",
    "                    time_major=False,\n",
    "                    dtype=tf.float32)                \n",
    "            else:\n",
    "                enc_cell_fw = tf.contrib.rnn.DropoutWrapper(\n",
    "                    self.config.cell(self.config.hidden_size),\n",
    "                    output_keep_prob=self.config.output_keep_prob)\n",
    "                \n",
    "                enc_cell_fw = tf.contrib.rnn.DeviceWrapper(enc_cell_fw, device=self._get_next_gpu())\n",
    "\n",
    "                gpu2 = self._get_next_gpu()\n",
    "\n",
    "                enc_cell_bw = tf.contrib.rnn.DropoutWrapper(\n",
    "                    self.config.cell(self.config.hidden_size),\n",
    "                    output_keep_prob=self.config.output_keep_prob)\n",
    "                \n",
    "                enc_cell_bw = tf.contrib.rnn.DeviceWrapper(enc_cell_bw, device=gpu2)\n",
    "\n",
    "                enc_outputs, enc_states = tf.nn.bidirectional_dynamic_rnn(enc_cell_fw, \n",
    "                                                                          enc_cell_bw, \n",
    "                                                                          enc_emb_inputs,\n",
    "                                                                          self.inputs_len,\n",
    "                                                                          dtype=tf.float32)\n",
    "                enc_outputs = tf.concat(enc_outputs,2)\n",
    "                enc_state   = tf.add(enc_states[0], enc_states[1])\n",
    "                \n",
    "                enc_cell = tf.contrib.rnn.DeviceWrapper(\n",
    "                        tf.contrib.rnn.DropoutWrapper(\n",
    "                            self.config.cell(num_units=self.config.hidden_size),\n",
    "                            output_keep_prob=self.config.output_keep_prob),\n",
    "                        device=gpu2)\n",
    "\n",
    "                # multi rnn\n",
    "                if self.config.layers > 2:\n",
    "                    enc_cell = [enc_cell]\n",
    "                    for _ in range(self.config.layers-2):\n",
    "                        enc_cell.append(tf.contrib.rnn.DeviceWrapper(\n",
    "                            tf.contrib.rnn.ResidualWrapper(\n",
    "                                tf.contrib.rnn.DropoutWrapper(\n",
    "                                    self.config.cell(num_units=self.config.hidden_size)),\n",
    "                                    output_keep_prob=self.config.output_keep_prob),\n",
    "                            device=self._get_next_gpu()))\n",
    "\n",
    "                    enc_cell = tf.contrib.rnn.MultiRNNCell(enc_cell)\n",
    "                    \n",
    "                \n",
    "                self.enc_outputs, self.enc_last_state = tf.nn.dynamic_rnn(\n",
    "                    cell=enc_cell,\n",
    "                    inputs=enc_outputs,\n",
    "                    sequence_length=self.inputs_len,\n",
    "                    time_major=False,\n",
    "                    dtype=tf.float32)\n",
    "                \n",
    "                if type(self.enc_last_state) is tuple:\n",
    "                    self.enc_last_state = (enc_state,) + self.enc_last_state\n",
    "                else:\n",
    "                    self.enc_last_state = (enc_state, self.enc_last_state)\n",
    "                \n",
    "    # decoder layer\n",
    "    def _add_decoder(self):\n",
    "        with tf.variable_scope('Decoder') as scope:\n",
    "            cells = []\n",
    "            if self.config.layers > 1:\n",
    "                for i in range(self.config.layers):\n",
    "                    if i == 0:\n",
    "                        cells.append(tf.contrib.rnn.DeviceWrapper(\n",
    "                            self.config.cell(self.config.hidden_size), \n",
    "                            device=self._get_next_gpu()))\n",
    "                    else:\n",
    "                        cells.append(tf.contrib.rnn.DeviceWrapper(\n",
    "                            tf.contrib.rnn.ResidualWrapper(\n",
    "                                self.config.cell(num_units=self.config.hidden_size)),\n",
    "                            device=self._get_next_gpu()))\n",
    "\n",
    "                self.dec_cell = tf.contrib.rnn.MultiRNNCell(cells)\n",
    "            else:\n",
    "                self.dec_cell = tf.contrib.rnn.DeviceWrapper(\n",
    "                                    self.config.cell(self.config.hidden_size), \n",
    "                                    device=self._get_next_gpu())\n",
    "            \n",
    "            if self.config.attention:\n",
    "                attn_mech = tf.contrib.seq2seq.LuongAttention(\n",
    "                        num_units=self.config.attn_size,\n",
    "                        memory=self.enc_outputs,\n",
    "                        memory_sequence_length=self.inputs_len,\n",
    "                        name='LuongAttention')\n",
    "\n",
    "                self.dec_cell = tf.contrib.seq2seq.AttentionWrapper(\n",
    "                        cell=self.dec_cell,\n",
    "                        attention_mechanism=attn_mech,\n",
    "                        attention_layer_size=self.config.attn_size,\n",
    "                        name='Attention_Wrapper')\n",
    "                \n",
    "                attention_zero = self.dec_cell.zero_state(batch_size=self.batch_size, dtype=tf.float32)\n",
    "                \n",
    "                # last_enc_state wrapper\n",
    "                self.initial_state = attention_zero.clone(cell_state=self.enc_last_state)\n",
    "            else:\n",
    "                self.initial_state = self.enc_last_state\n",
    "\n",
    "            self.dec_W_emb = tf.get_variable('de_embedding', \n",
    "                                             initializer=tf.random_uniform([len(target_letters),\n",
    "                                                                            self.config.dec_embedding_dim]),\n",
    "                                             dtype=tf.float32)\n",
    "                \n",
    "            self.output_layer = Dense(len(target_letters), name='output_projection')\n",
    "            if self.mode == 'training': # training layer\n",
    "                if self.rl_enable:\n",
    "                    self.sampling_predictions, self.greedy_predictions, self.loss = self._add_rl_training_layer(scope)\n",
    "                else:\n",
    "                    self.predictions, self.loss = self._add_training_layer(scope)\n",
    "                \n",
    "            else: # inference layer\n",
    "                self.predictions = self._add_inference_layer()     \n",
    "\n",
    "    # inference layer\n",
    "    def _add_inference_layer(self):\n",
    "        # inference layer\n",
    "        sequence_start = [BOS_ix_target]\n",
    "        start_tokens = tf.tile(sequence_start, [self.batch_size], name='start_tokens')\n",
    "\n",
    "        inference_helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(\n",
    "            embedding=self.dec_W_emb,\n",
    "            start_tokens=start_tokens,\n",
    "            end_token=EOS_ix_target) \n",
    "\n",
    "        inference_decoder = tf.contrib.seq2seq.BasicDecoder(\n",
    "            cell=self.dec_cell,\n",
    "            helper=inference_helper,\n",
    "            initial_state=self.initial_state,\n",
    "            output_layer=self.output_layer)\n",
    "\n",
    "        inference_outputs, _, _ = tf.contrib.seq2seq.dynamic_decode(\n",
    "            inference_decoder,\n",
    "            output_time_major=False,\n",
    "            impute_finished=True,\n",
    "            maximum_iterations=self.max_target_len)\n",
    "            \n",
    "        predictions = inference_outputs.sample_id\n",
    "        return predictions\n",
    "    \n",
    "    # training layer\n",
    "    def _add_training_layer(self, scope):\n",
    "        # training_layer\n",
    "        self.max_target_len = tf.reduce_max(self.targets_length, name='max_target_len')\n",
    "        \n",
    "        dec_inputs = tf.concat([tf.zeros_like(self.targets[:,:1])+BOS_ix_target,\n",
    "                                          self.targets[:,:-1]],axis=1)\n",
    "        \n",
    "        dec_emb_inputs = tf.nn.embedding_lookup(\n",
    "            self.dec_W_emb, dec_inputs, name='emb_inputs')\n",
    "\n",
    "        training_helper = tf.contrib.seq2seq.TrainingHelper(\n",
    "            inputs=dec_emb_inputs,\n",
    "            sequence_length=self.targets_length,\n",
    "            time_major=False,\n",
    "            name='training_helper')\n",
    "\n",
    "        training_decoder = tf.contrib.seq2seq.BasicDecoder(\n",
    "            cell=self.dec_cell,\n",
    "            helper=training_helper,\n",
    "            initial_state=self.initial_state,\n",
    "            output_layer=self.output_layer)\n",
    "\n",
    "        max_target_len = tf.reduce_max(self.targets_length, name='max_target_len')\n",
    "        \n",
    "        train_outputs, _, _ = tf.contrib.seq2seq.dynamic_decode(\n",
    "            training_decoder,\n",
    "            output_time_major=False,\n",
    "            impute_finished=True,\n",
    "            maximum_iterations=max_target_len)\n",
    "            \n",
    "        # predictions\n",
    "        predictions = train_outputs.sample_id\n",
    "\n",
    "        masks = tf.sequence_mask(self.targets_length, self.max_target_len, dtype=tf.float32, name='masks')\n",
    "\n",
    "        # loss\n",
    "        loss = tf.contrib.seq2seq.sequence_loss(logits=train_outputs.rnn_output, \n",
    "                                                targets=self.targets,\n",
    "                                                weights=masks, \n",
    "                                                name='batch_loss')        \n",
    "        return predictions, loss\n",
    "        \n",
    "    def _add_rl_training_layer(self, scope):\n",
    "        # RL training_layer\n",
    "        sequence_start = [BOS_ix_target]\n",
    "        start_tokens = tf.tile(sequence_start, [self.batch_size], name='start_tokens')\n",
    "        \n",
    "        #greedy decoding\n",
    "        greedy_helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(\n",
    "            embedding=self.dec_W_emb,\n",
    "            start_tokens=start_tokens,\n",
    "            end_token=EOS_ix_target) \n",
    "\n",
    "        greedy_decoder = tf.contrib.seq2seq.BasicDecoder(\n",
    "            cell=self.dec_cell,\n",
    "            helper=greedy_helper,\n",
    "            initial_state=self.initial_state,\n",
    "            output_layer=self.output_layer)\n",
    "\n",
    "        greedy_dec_outputs, _, _ = tf.contrib.seq2seq.dynamic_decode(\n",
    "            greedy_decoder,\n",
    "            output_time_major=False,\n",
    "            impute_finished=True,\n",
    "            maximum_iterations=self.max_target_len)\n",
    "\n",
    "        # greedy predictions\n",
    "        greedy_predictions = greedy_dec_outputs.sample_id\n",
    "        greedy_masks = self._get_mask_by_eos(tf.equal(greedy_predictions, EOS_ix_target))\n",
    "        \n",
    "        input_masks = self._get_mask_by_eos(tf.equal(self.input_ids, EOS_ix_source))\n",
    "        \n",
    "        baseline = tf.py_func(compute_levenshtein, [self.input_ids,\n",
    "                                                    input_masks,\n",
    "                                                    greedy_predictions,\n",
    "                                                    greedy_masks], Tout=tf.float32)\n",
    "        \n",
    "        baseline = tf.stop_gradient(tf.reshape(baseline, [self.batch_size]))\n",
    "        \n",
    "        scope.reuse_variables()\n",
    "\n",
    "        #sampling decoding\n",
    "        training_sampling_helper = tf.contrib.seq2seq.SampleEmbeddingHelper(\n",
    "            embedding=self.dec_W_emb,\n",
    "            start_tokens=start_tokens,\n",
    "            end_token=EOS_ix_target,\n",
    "            seed=1234)\n",
    "\n",
    "        training_sampling_decoder = tf.contrib.seq2seq.BasicDecoder(\n",
    "            cell=self.dec_cell,\n",
    "            helper=training_sampling_helper,\n",
    "            initial_state=self.initial_state,\n",
    "            output_layer=self.output_layer)\n",
    "\n",
    "        train_outputs, _, _ = tf.contrib.seq2seq.dynamic_decode(\n",
    "            training_sampling_decoder,\n",
    "            output_time_major=False,\n",
    "            impute_finished=True,\n",
    "            maximum_iterations=self.max_target_len)\n",
    "\n",
    "        # predictions\n",
    "        predictions = train_outputs.sample_id\n",
    "        \n",
    "        # mask\n",
    "        sampling_masks = self._get_mask_by_eos(tf.equal(predictions, EOS_ix_target))\n",
    "\n",
    "        rewards = tf.py_func(compute_levenshtein, [self.input_ids,\n",
    "                                                   input_masks,\n",
    "                                                   predictions,\n",
    "                                                   sampling_masks], Tout=tf.float32)\n",
    "        rewards = tf.stop_gradient(tf.reshape(rewards, [self.batch_size]))\n",
    "        \n",
    "        # advantage\n",
    "        with tf.control_dependencies([baseline, rewards]):\n",
    "            self.advantage = -rewards + baseline\n",
    "\n",
    "            # loss\n",
    "            #logprobs, advantage, weights\n",
    "            loss = rl_loss(logits=train_outputs.rnn_output, \n",
    "                           targets=predictions,\n",
    "                           advantage=self.advantage, \n",
    "                           weights=sampling_masks, \n",
    "                           name='rl_loss')\n",
    "\n",
    "            return predictions, greedy_predictions, loss\n",
    "\n",
    "    # optimizing layer\n",
    "    def _add_optimizer(self):\n",
    "        with tf.variable_scope('Optimizer') as scope:\n",
    "            def _clip_gradients(grads_and_vars):\n",
    "                \"\"\"Clips gradients by global norm.\"\"\"\n",
    "                gradients, variables = zip(*grads_and_vars)\n",
    "                clipped_gradients, _ = tf.clip_by_global_norm(\n",
    "                    gradients, self.config.optimizer_clip_gradients)\n",
    "                return list(zip(clipped_gradients, variables))\n",
    "            \n",
    "            self.train_op = tf.contrib.layers.optimize_loss(loss=self.loss, \n",
    "                                                            global_step=tf.contrib.framework.get_global_step(),\n",
    "                                                            learning_rate=self.config.learning_rate, \n",
    "                                                            clip_gradients=_clip_gradients,\n",
    "                                                            optimizer=self.config.optimizer)\n",
    "\n",
    "    # translate a word\n",
    "    def translate(self, sess, word, sample=False):\n",
    "        #if os.path.isfile(self.config.ckpt_path):\n",
    "        #    self.restore(sess)\n",
    "            \n",
    "        assert word.endswith(END)\n",
    "        word_len = np.array([len(word)])\n",
    "        word_ix = as_matrix([word.lower()],source_to_ix)\n",
    "        feed_dict = {self.input_ids: word_ix, self.inputs_len: word_len}\n",
    "        if sample:\n",
    "            outputs = sess.run(self.predictions, feed_dict=feed_dict)\n",
    "        else:\n",
    "            outputs = sess.run(self.predictions, feed_dict=feed_dict)\n",
    "        trans = list(map(target_letters.__getitem__, outputs[0]))\n",
    "        if END in trans:\n",
    "            trans = trans[:trans.index(END)+1]\n",
    "            \n",
    "        return ''.join(trans)\n",
    "    \n",
    "    # infer method(for a batch)\n",
    "    def infer(self, sess, inputs, inputs_len):\n",
    "        #if os.path.isfile(self.config.ckpt_path):\n",
    "        #    self.restore(sess)\n",
    "        \n",
    "        feed_dict = {self.input_ids: inputs, self.inputs_len: inputs_len}\n",
    "        \n",
    "        outputs = sess.run(self.predictions, feed_dict=feed_dict)\n",
    "    \n",
    "        return outputs\n",
    "    \n",
    "    # train a step\n",
    "    def train_step(self, sess, inputs, inputs_len, targets, targets_len):\n",
    "        feed_dict = {self.input_ids: inputs, self.inputs_len: inputs_len,\n",
    "                    self.target_ids: targets, self.targets_len: targets_len}\n",
    "        _, loss = sess.run([self.train_op, self.loss], feed_dict=feed_dict)\n",
    "        #loss = sess.run(self.advantage, feed_dict=feed_dict)\n",
    "        return loss\n",
    "    \n",
    "    def summary(self):\n",
    "        summary_writer = tf.summary.FileWriter(\n",
    "            logdir=self.config.ckpt_path, graph=tf.get_default_graph())\n",
    "               \n",
    "    def restore(self, sess, ckpt_path=None):\n",
    "        if ckpt_path:\n",
    "            self.saver.restore(sess, ckpt_path)\n",
    "        else:\n",
    "            self.saver.restore(sess, self.config.ckpt_path)\n",
    "        print('Restore Finished!')\n",
    "        \n",
    "    def save(self, sess, save_path=None):\n",
    "        if save_path:\n",
    "            self.saver.save(sess, save_path)\n",
    "            print(f'Saving model at {save_path}')\n",
    "        else:\n",
    "            self.saver.save(sess, self.config.ckpt_path)\n",
    "            print(f'Saving model at {save_path}')\n",
    "\n",
    "            \n",
    "    def rl_train_step(self, sess, inputs, inputs_len, targets, targets_len):\n",
    "        \n",
    "        feed_dict = {self.input_ids: inputs, self.inputs_len: inputs_len,\n",
    "                    self.target_ids: targets, self.targets_len: targets_len}\n",
    "        \n",
    "        #sampling_preds, greedy_preds = sess.run([self.predictions, self.greedy_predictions], \n",
    "        #                                        feed_dict=feed_dict)\n",
    "        \n",
    "        #print(sampling_preds)\n",
    "        #print(greedy_preds)\n",
    "        #sampling_masks = get_mask_by_eos(np.equal(sampling_preds,EOS_ix_target))\n",
    "        #greedy_masks = get_mask_by_eos(np.equal(greedy_preds,EOS_ix_target))\n",
    "        #input_masks = get_mask_by_eos(np.equal(inputs, EOS_ix_source))\n",
    "        \n",
    "        #rewards = -compute_levenshtein(inputs, input_masks, sampling_preds, sampling_masks)\n",
    "        #baseline = -compute_levenshtein(inputs, input_masks, greedy_preds, greedy_masks)\n",
    "\n",
    "        #advantage = rewards - baseline\n",
    "        #print(advantage)\n",
    "        \n",
    "        #feed_dict.update({self.advantage:advantage})\n",
    "\n",
    "        loss, _ = sess.run([self.loss, self.train_op], feed_dict=feed_dict)\n",
    "        \n",
    "        #print(\"advantage:\", advantage)\n",
    "        #print(\"logprobs:\", logprobs)\n",
    "        #print(\"w:\", weights)\n",
    "        #print(\"loss:\", loss)\n",
    "        return loss\n",
    "        \n",
    "    def _calculate_advantage(self, inputs, sampling_preds, greedy_preds):\n",
    "        \n",
    "        sampling_masks = get_mask_by_eos(np.equal(sampling_preds,EOS_ix_target))\n",
    "        greedy_masks = get_mask_by_eos(np.equal(greedy_preds,EOS_ix_target))\n",
    "        input_masks = get_mask_by_eos(np.equal(inputs, EOS_ix_source))\n",
    "        \n",
    "        rewards = -compute_levenshtein(inputs, input_masks, sampling_preds, sampling_masks)\n",
    "        baseline = -compute_levenshtein(inputs, input_masks, greedy_preds, greedy_masks)\n",
    "\n",
    "        advantage = rewards - baseline\n",
    "        return advantage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:אנרכיזם;\n",
      "y_sampled:צěטטטטטטטטטììììììììì\n",
      "y_greedy:צěטטטטטטטטטììììììììì\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#test untrained model\n",
    "#should be random\n",
    "tf.reset_default_graph()\n",
    "print ('x:'+all_words[0])\n",
    "seq2seq = Seq2SeqModel(hparams, mode='inference')\n",
    "seq2seq.build_graph()\n",
    "with tf.Session() as sess:\n",
    "    #seq2seq.restore(sess)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print ('y_sampled:'+seq2seq.translate(sess, all_words[0],sample=True))\n",
    "    print ('y_greedy:'+seq2seq.translate(sess, all_words[0]))\n",
    "#praise Cthulhu!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score 함수\n",
    "LogLikelihood는 모델 성능 평가에 좋지 않다.\n",
    "- 제로 확률이 한번 예측 되면, 전체 모델을 망치지 말아야 한다.\n",
    "- 여러개의 바른 답이 있다면 단지 하나의 번역을 배우는 것만으로 충분하다.\n",
    "- 한 단계마다 가장 있을법한 음소를 가지는지 출력해???\n",
    "\n",
    "그러므로, 우리는 최소 Levenshten distance를 사용할 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import editdistance\n",
    "\n",
    "def get_distance(word, trans):\n",
    "    \"\"\"\n",
    "    워드와 예측된 번역을 입력으로 하고 바른 번역에 얼마나 가까운지 edit distance를 평가한다.\n",
    "    \"\"\"\n",
    "    #print(word)\n",
    "    references = word_to_translation[word]\n",
    "    #print(references)\n",
    "    #print(trans)\n",
    "    assert len(references) !=0, \"word/unknown word\"\n",
    "    return min(editdistance.eval(trans, ref) for ref in references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score(sess, model, bsize=100):\n",
    "    \"\"\"\n",
    "    bszie의 랜덤 샘플에 대해 levenshtein distance를 계산하는 함수\n",
    "    \"\"\"\n",
    "    batch_words = np.random.choice(test_words, size=(bsize,)) \n",
    "    #for word in batch_words:\n",
    "    #    print(word)\n",
    "    predictions = [model.translate(sess, word) for word in batch_words]\n",
    "    #for p in predictions:\n",
    "    #    print(p)\n",
    "    #print(predictions)\n",
    "    distances = [get_distance(word, prediction) for (word, prediction) in zip(batch_words, predictions)]    \n",
    "    return np.array(distances,dtype='float32')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20.02, 19.98, 19.99, 20.030001, 20.030001, 20.01, 20.030001, 20.01, 20.02, 20.0]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    #should be around 5-50 and decrease rapidly :)\n",
    "    result = [score(sess, seq2seq, 100).mean() for _ in range(10)]\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Step 4\n",
    "def compute_bleu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Supervised pre-training\n",
    "여기에서 로그 우도를 최대화 함으로써 모델을 학습하는 함수를 정의하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeQAAAEICAYAAACOKIcAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nsqIoiqLUASrIiqIoilIH/H9k2heOAEMsZQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f27ca1711d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llh=0.834, mean score=5.406\n",
      "INFO:tensorflow:Restoring parameters from ./ckpt_dir/model2.ckpt\n",
      "Restore Finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 23641/25000 [49:48<01:55, 11.75it/s]"
     ]
    }
   ],
   "source": [
    "\n",
    "from IPython.display import clear_output\n",
    "from tqdm import tqdm,trange #or use tqdm_notebook,tnrange\n",
    "\n",
    "loss_history=[]\n",
    "editdist_history = []\n",
    "tf.reset_default_graph()\n",
    "seq2seq = Seq2SeqModel(hparams)\n",
    "seq2seq.build_graph()\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "#seq2seq.restore(saver, sess)\n",
    "for i in trange(25000):\n",
    "    loss_history.append(\n",
    "             seq2seq.train_step(sess, *sample_batch(train_words,word_to_translation,32)))\n",
    "        \n",
    "    if (i+1)%REPORT_FREQ==0:\n",
    "    #if False:\n",
    "            seq2seq.save(sess)\n",
    "            sess.close()\n",
    "            \n",
    "            tf.reset_default_graph()\n",
    "            sess = tf.Session()\n",
    "            \n",
    "            seq2seq_inference = Seq2SeqModel(hparams, mode='inference')\n",
    "            seq2seq_inference.build_graph()\n",
    "            seq2seq_inference.restore(sess)\n",
    "                \n",
    "            clear_output(True)\n",
    "            current_scores = score(sess, seq2seq_inference)\n",
    "            editdist_history.append(current_scores.mean())\n",
    "            plt.figure(figsize=(8,4))\n",
    "            plt.subplot(121)\n",
    "            plt.title('val score  distribution')\n",
    "            plt.hist(current_scores, bins = 20)\n",
    "            plt.subplot(122)\n",
    "            plt.title('val score / traning time')\n",
    "            plt.plot(editdist_history)\n",
    "            plt.grid()\n",
    "            plt.show()\n",
    "            print(\"llh=%.3f, mean score=%.3f\"%(np.mean(loss_history[-10:]),np.mean(editdist_history[-10:])))\n",
    "            tf.reset_default_graph()\n",
    "            seq2seq = Seq2SeqModel(hparams)\n",
    "            seq2seq.build_graph()\n",
    "            sess = tf.Session()\n",
    "            seq2seq.restore(sess)\n",
    "\n",
    "seq2seq.save(sess)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./ckpt_dir/model2.ckpt\n",
      "Restore Finished!\n",
      "עלי נאסר; -> ali nassar;\n",
      "קטגוריה:בלפסט; -> balpast;\n",
      "ארבינקא; -> arbinka;\n",
      "זיכרון נוהלי; -> protummer clock;\n",
      "scar tissue; -> scar tisses;\n",
      "עמק האלבה בדרזדן; -> dardad al dark ar ar\n",
      "ז'ורז' בולנז'ה; -> georges boulenger;\n",
      "מילקן; -> milken;\n",
      "כביש 73; -> highway 73;\n",
      "אלין; -> elin;\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "seq2seq_inference = Seq2SeqModel(hparams, mode='inference')\n",
    "seq2seq_inference.build_graph()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    seq2seq_inference.restore(sess)\n",
    "    \n",
    "    for word in train_words[:10]:\n",
    "        print(\"%s -> %s\"%(word,seq2seq_inference.translate(sess, word)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Step 5: 정책 그라디언트(Policy gradient )\n",
    "\n",
    "손실(loss) 함수를 정의 할 필요가 있다.\n",
    "\n",
    "우리 작업은 단어와 번역 행렬들을 입력으로 가지고 그것들을 실제 단어 그리고 음절로 변환하고 위에 get_distance 함수를 통해서 min-levenshtein를 계산하는 _compute_levenshtein을 구현하는 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_levenshtein(words_ix,words_mask,trans_ix,trans_mask):\n",
    "    \"\"\"\n",
    "    예측된 번역에 대한 levenshtein 손실을 계산하는 커스텀 theano 연산이다.\n",
    "    \n",
    "    Params:\n",
    "    - words_ix - 문자 인덱스 행렬, shape=[batch_size, word_length]\n",
    "    - words_mask - 0과1로 구성된 행렬,\n",
    "        1은 단어는 아직 끝나지 않았음을 의미한다.\n",
    "        0은 단어는 이미 끝나고 이것은 패딩이다는 것을 의미한다.\n",
    "    -trans_ix - 결과 문자 인덱스 행렬, shape=[batch_size,translation_length]\n",
    "    -trans_mask - 0과1로 구성된 행렬 word_mask와 유사하다. 그러나 tans_ix를 위한 것이다.\n",
    "    \n",
    "    \"\"\"\n",
    "    words = []\n",
    "    for i, letters_ix in enumerate(words_ix):\n",
    "        word = ''.join([source_letters[letter_ix] for letter_ix in letters_ix][:int(sum(words_mask[i]))])\n",
    "        words.append(word)\n",
    "    \n",
    "    assert type(words) is list\n",
    "    assert type(words[0]) is str \n",
    "    assert len(words)==len(words_ix)\n",
    "    #convert translations to lists    \n",
    "    translations = []\n",
    "    for i, tran_ix in enumerate(trans_ix):\n",
    "        tran = ''.join([target_letters[letter_ix] for letter_ix in tran_ix][:int(sum(trans_mask[i]))])\n",
    "        translations.append(tran)\n",
    "    \n",
    "    assert type(translations) is list\n",
    "    assert type(translations[0]) is str\n",
    "    assert len(translations)==len(trans_ix)\n",
    "\n",
    "    distances = [get_distance(w,t) for w, t in zip(words, translations)]\n",
    "    \n",
    "    assert type(distances) in (list,tuple,np.ndarray) and len(distances) == len(words_ix)\n",
    "    \n",
    "    distances = np.array(list(distances),dtype='float32')\n",
    "    return distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#test suite\n",
    "#sample random batch of (words, correct trans, wrong trans)\n",
    "batch_words = np.random.choice(train_words, size=100 )\n",
    "batch_trans = list(map(random.choice,map(word_to_translation.get,batch_words )))\n",
    "batch_trans_wrong = np.random.choice(all_translations,size=100)\n",
    "\n",
    "batch_words_ix = as_matrix(batch_words,source_to_ix)\n",
    "batch_trans_ix = as_matrix(batch_trans,target_to_ix)\n",
    "batch_trans_wrong_ix = as_matrix(batch_trans_wrong,target_to_ix)\n",
    "\n",
    "batch_words_mask = get_mask_by_eos(np.equal(batch_words_ix,EOS_ix_source))\n",
    "batch_trans_mask = get_mask_by_eos(np.equal(batch_trans_ix,EOS_ix_target))\n",
    "batch_trans_wrong_mask = get_mask_by_eos(np.equal(batch_trans_wrong_ix,EOS_ix_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#assert compute_levenshtein is zero for ideal translations\n",
    "correct_answers_score = compute_levenshtein(batch_words_ix,batch_words_mask,\n",
    "                                            batch_trans_ix,batch_trans_mask)\n",
    "\n",
    "assert np.all(correct_answers_score==0),\"a perfect translation got nonzero levenshtein score!\"\n",
    "\n",
    "print(\"Everything seems alright!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#assert compute_levenshtein matches actual scoring function\n",
    "wrong_answers_score = compute_levenshtein(batch_words_ix,batch_words_mask,\n",
    "                                            batch_trans_wrong_ix,batch_trans_wrong_mask)\n",
    "\n",
    "true_wrong_answers_score = np.array(list(map(get_distance,batch_words,batch_trans_wrong)))\n",
    "\n",
    "assert np.all(wrong_answers_score==true_wrong_answers_score),\"for some word symbolic levenshtein is different from actual levenshtein distance\"\n",
    "\n",
    "print(\"Everything seems alright!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self-critical policy gradient\n",
    "이 섹션에서, self-critical sequence학습이라고 하는 알고리즘을 구현할 것이다.\n",
    "이 알고리즘은 특별한 베이스라인을 가진 바닐라 정책 그라디언트이다.\n",
    "\n",
    "$$ \\nabla J = E_{x \\sim p(s)} E_{y \\sim \\pi(y|x)} \\nabla log \\pi(y|x) \\cdot (R(x,y) - b(x)) $$\n",
    "\n",
    "여기서 R(x,y)는 네가티브 levenshtein distance 이다(그것을 최소화 하기 때문이다). 베이스라인 b(x)는 단어 x에 대하 모델이 얼마나 되는지 나타낸다. 실제적으로, 이것은 그라디(greedy) 번역 점수로써 베이스라인을 계산한다는 것을 의미한다, $b(x) = R(x,y_{greedy}(x)) $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create params\n",
    "def create_hparams():\n",
    "    return HParams(\n",
    "        cell=hparams.cell,\n",
    "        batch_size=hparams.batch_size,\n",
    "        layers=hparams.layers,\n",
    "        attention=hparams.attention,\n",
    "        eval_batch_size=hparams.eval_batch_size,\n",
    "        optimizer=hparams.optimizer,\n",
    "        optimizer_clip_gradients = hparams.optimizer_clip_gradients,\n",
    "        learning_rate=0.00001,\n",
    "        enc_embedding_dim=hparams.enc_embedding_dim,\n",
    "        dec_embedding_dim=hparams.dec_embedding_dim,\n",
    "        hidden_size=hparams.hidden_size,\n",
    "        attn_size=hparams.attn_size,\n",
    "        output_keep_prob=hparams.output_keep_prob,\n",
    "        max_source_len=hparams.max_source_len,\n",
    "        max_target_len=MAX_OUTPUT_LENGTH,\n",
    "        ckpt_path='./ckpt_dir/model2.ckpt')\n",
    "\n",
    "hparams2 = create_hparams()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 정책 그라디언트 학습(Policy gradient training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm,trange #or use tqdm_notebook,tnrange\n",
    "\n",
    "#REPORT_FREQ=1\n",
    "\n",
    "tf.reset_default_graph()\n",
    "seq2seq = Seq2SeqModel(hparams2,rl_enable=True)\n",
    "seq2seq.build_graph()\n",
    "\n",
    "sess = tf.Session()\n",
    "seq2seq.restore(sess)\n",
    "    #tvars = tf.trainable_variables()\n",
    "    #tvars_vals = sess.run(tvars)\n",
    "    \n",
    "    #for var, val in zip(tvars, tvars_vals):\n",
    "    #    print(var.name, val)\n",
    "    \n",
    "for i in trange(100000):\n",
    "        #for i in trange(200):\n",
    "        inputs, inputs_len, targets, targets_len = sample_batch(train_words, word_to_translation,1)\n",
    "        loss_history.append(\n",
    "            seq2seq.rl_train_step(sess, inputs, inputs_len, targets, targets_len)\n",
    "            )\n",
    "        #print(\"infer:\", seq2seq_inferencer.infer(sess, inputs, inputs_len))\n",
    "        \n",
    "        if (i+1)%REPORT_FREQ==0:\n",
    "        #if (i+1)%10 == 0:\n",
    "            #seq2seq.save(sess)\n",
    "            sess.close()\n",
    "            \n",
    "            tf.reset_default_graph()\n",
    "            seq2seq_inferencer = Seq2SeqModel(hparams2, mode='inference')\n",
    "            seq2seq_inferencer.build_graph()\n",
    "            sess = tf.Session()\n",
    "            seq2seq_inferencer.restore(sess)\n",
    "            \n",
    "            clear_output(True)\n",
    "            current_scores = score(sess, seq2seq_inferencer)\n",
    "            editdist_history.append(current_scores.mean())\n",
    "            plt.figure(figsize=(8,4))\n",
    "            plt.subplot(121)\n",
    "            plt.title('val score distribution')\n",
    "            plt.hist(current_scores, bins = 20)\n",
    "            plt.subplot(122)\n",
    "            plt.title('val score / traning time')\n",
    "            plt.plot(editdist_history)\n",
    "            plt.grid()\n",
    "            plt.show()\n",
    "            print(\"J=%.3f, mean score=%.3f\"%(np.mean(loss_history[-10:]),np.mean(editdist_history[-10:])))\n",
    "            sess.close()\n",
    "            tf.reset_default_graph()\n",
    "            \n",
    "            seq2seq = Seq2SeqModel(hparams2,rl_enable=True)\n",
    "            seq2seq.build_graph()\n",
    "\n",
    "            sess = tf.Session()\n",
    "            seq2seq.restore(sess)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./ckpt_dir/model.ckpt\n",
      "Restore Finished!\n",
      "example;\n"
     ]
    }
   ],
   "source": [
    "seq2seq_inferencer = Seq2SeqModel(hparams2, mode='inference')\n",
    "seq2seq_inferencer.build_graph()\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    seq2seq_inferencer.restore(saver, sess)\n",
    "    print(seq2seq_inferencer.translate(sess, \"EXAMPLE;\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#predicted_translations = list(map(model.translate,tqdm(test_words)))\n",
    "#distances = map(get_score,test_words,predicted_translations)\n",
    "\n",
    "#print (\"Mean Levenshtein distance:\",np.mean(distances))\n",
    "#print (\"Median Levenshtein distance:\",np.median(distances))\n",
    "#plt.hist(distances,range=[0,10]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
